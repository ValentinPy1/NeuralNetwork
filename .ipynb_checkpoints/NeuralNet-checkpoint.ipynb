{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size, input_size)\n",
    "        self.bias = np.random.randn(output_size, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.dot(self.weights, self.input) + self.bias\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        weights_gradient = np.dot(output_gradient, self.input.T)\n",
    "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.bias -= learning_rate * output_gradient\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return self.activation(self.input)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return np.multiply(output_gradient, self.activation_prime(self.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Activation):\n",
    "    def __init__(self):\n",
    "        def tanh(x):\n",
    "            return np.tanh(x)\n",
    "\n",
    "        def tanh_prime(x):\n",
    "            return 1 - np.tanh(x) ** 2\n",
    "\n",
    "        super().__init__(tanh, tanh_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def loss(self, y_true, y_pred):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def gradient(self, y_true, y_pred):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class MeanSquaredError(Loss):\n",
    "    def loss(self, y_true, y_pred):\n",
    "        return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "    def gradient(self, y_true, y_pred):\n",
    "        return 2 * (y_pred - y_true) / y_true.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(Layer):\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def backward(self, output_error, learning_rate):\n",
    "        for layer in reversed(self.layers):\n",
    "            output_error = layer.backward(output_error, learning_rate)\n",
    "        return output_error\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, network, loss):\n",
    "        self.network = Network(network)\n",
    "        self.loss = loss\n",
    "    \n",
    "    def train(self, x_train, y_train, epochs, learning_rate, verbose=False):\n",
    "        for epoch in range(epochs):\n",
    "            for x, y in zip(x_train, y_train):\n",
    "                output = self.network.forward(x)\n",
    "                loss = self.loss.loss(y, output)\n",
    "                loss_gradient = self.loss.gradient(y, output)\n",
    "                self.network.backward(loss_gradient, learning_rate)\n",
    "            if verbose:\n",
    "                print('Epoch: %d, Loss: %.3f' % (epoch + 1, loss))\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        if len(x_test.shape) == 1:\n",
    "            return self.network.forward(x_test.reshape(-1, 1))\n",
    "        y_pred = []\n",
    "        for x in x_test:\n",
    "            y_pred.append(self.network.forward(x.reshape(-1, 1)))\n",
    "        return np.array(y_pred).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(Layer):\n",
    "    def __init__(self, input_shape, kernel_size, depth):\n",
    "        input_depth, input_height, input_width = input_shape\n",
    "        self.depth = depth\n",
    "        self.input_shape = input_shape\n",
    "        self.input_depth = input_depth\n",
    "        self.output_shape = (depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "        self.kernels_shape = (depth, input_depth, kernel_size, kernel_size)\n",
    "        self.kernels = np.random.randn(*self.kernels_shape)\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = np.copy(self.biases)\n",
    "        for i in range(self.depth):\n",
    "            for j in range(self.input_depth):\n",
    "                self.output[i] += signal.correlate2d(self.input[j], self.kernels[i, j], \"valid\")\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        kernels_gradient = np.zeros(self.kernels_shape)\n",
    "        input_gradient = np.zeros(self.input_shape)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            for j in range(self.input_depth):\n",
    "                kernels_gradient[i, j] = signal.correlate2d(self.input[j], output_gradient[i], \"valid\")\n",
    "                input_gradient[j] += signal.convolve2d(output_gradient[i], self.kernels[i, j], \"full\")\n",
    "\n",
    "        self.kernels -= learning_rate * kernels_gradient\n",
    "        self.biases -= learning_rate * output_gradient\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(Layer):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, input):\n",
    "        return np.reshape(input, self.output_shape)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return np.reshape(output_gradient, self.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Activation):\n",
    "    def __init__(self):\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def sigmoid_prime(x):\n",
    "            s = sigmoid(x)\n",
    "            return s * (1 - s)\n",
    "\n",
    "        super().__init__(sigmoid, sigmoid_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCrossEntropy(Loss):\n",
    "    def loss(self, y_true, y_pred):\n",
    "        return -np.mean(np.multiply(y_true, np.log(y_pred)) + np.multiply(1 - y_true, np.log(1 - y_pred)))\n",
    "\n",
    "    def gradient(self, y_true, y_pred):\n",
    "        return np.divide(y_pred - y_true, np.multiply(y_pred, 1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x, y, limit):\n",
    "    # reshape and normalize input data\n",
    "    x = x.reshape(x.shape[0], 28 * 28, 1)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    # encode output which is a number in range [0,9] into a vector of size 10\n",
    "    # e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "    y = np.eye(10)[y]\n",
    "    y = y.reshape(y.shape[0], 10, 1)\n",
    "    return x[:limit], y[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.007\n",
      "Epoch: 2, Loss: 0.018\n",
      "Epoch: 3, Loss: 0.020\n",
      "Epoch: 4, Loss: 0.009\n",
      "Epoch: 5, Loss: 0.002\n",
      "Epoch: 6, Loss: 0.005\n",
      "Epoch: 7, Loss: 0.006\n",
      "Epoch: 8, Loss: 0.002\n",
      "Epoch: 9, Loss: 0.002\n",
      "Epoch: 10, Loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train = preprocess_data(x_train, y_train, 1000)\n",
    "x_test, y_test = preprocess_data(x_test, y_test, 1000)\n",
    "\n",
    "# neural network\n",
    "layers = [\n",
    "    Dense(28 * 28, 40),\n",
    "    Tanh(),\n",
    "    Dense(40, 10),\n",
    "    Sigmoid()\n",
    "]\n",
    "\n",
    "model = Model(layers, BinaryCrossEntropy())\n",
    "model.train(x_train, y_train, 10, 0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.798\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for x, y in zip(x_test, y_test):\n",
    "    x = x.reshape(784)\n",
    "    output = model.predict(x)\n",
    "    # print(\"Prediction: %d, Ground Truth: %d\" % (np.argmax(output), np.argmax(y)))\n",
    "    if np.argmax(output) == np.argmax(y):\n",
    "        correct += 1\n",
    "print(\"Accuracy: %.3f\" % (correct / len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.0\n",
      "1 : 0.0\n",
      "2 : 0.003\n",
      "3 : 0.003\n",
      "4 : 0.0\n",
      "5 : 0.0\n",
      "6 : 0.0\n",
      "7 : 0.004\n",
      "8 : 0.985\n",
      "9 : 0.007\n",
      "Prediction: 8\n",
      "Ground Truth: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "choosen = randint(0, 1000)\n",
    "plt.imshow(x_test[choosen].reshape(28, 28), cmap=\"gray\")\n",
    "prediction = model.predict(x_test[choosen].reshape(784))\n",
    "for i in range(10):\n",
    "    print(i, \":\", round(prediction[i][0], 3))\n",
    "print(\"Prediction:\", np.argmax(prediction))\n",
    "print(\"Ground Truth:\", np.argmax(y_test[choosen]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "fake_img = numpy.random.random((28,28))\n",
    "\n",
    "plt.imshow(fake_img, cmap='gray')\n",
    "ax  = plt.gca()\n",
    "fig = plt.gcf()\n",
    "\n",
    "linepoints = numpy.array([])\n",
    "\n",
    "def onclick(event):\n",
    "    print(event)\n",
    "    if event.button == 1:\n",
    "        global linepoints\n",
    "\n",
    "        x = event.xdata\n",
    "        y = event.ydata\n",
    "\n",
    "        linepoints = numpy.append(linepoints, x)\n",
    "        linepoints = numpy.append(linepoints, y)\n",
    "\n",
    "        if numpy.size(linepoints) == 4:\n",
    "            plt.plot((linepoints[0], linepoints[2]), (linepoints[1], linepoints[3]), '-')\n",
    "            linepoints = numpy.array([])\n",
    "            plt.show()\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
