{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size, input_size)\n",
    "        self.bias = np.random.randn(output_size, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.dot(self.weights, self.input) + self.bias\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        weights_gradient = np.dot(output_gradient, self.input.T)\n",
    "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.bias -= learning_rate * output_gradient\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return self.activation(self.input)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return np.multiply(output_gradient, self.activation_prime(self.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Activation):\n",
    "    def __init__(self):\n",
    "        def tanh(x):\n",
    "            return np.tanh(x)\n",
    "\n",
    "        def tanh_prime(x):\n",
    "            return 1 - np.tanh(x) ** 2\n",
    "\n",
    "        super().__init__(tanh, tanh_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def loss(self, y_true, y_pred):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def gradient(self, y_true, y_pred):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class MeanSquaredError(Loss):\n",
    "    def loss(self, y_true, y_pred):\n",
    "        return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "    def gradient(self, y_true, y_pred):\n",
    "        return 2 * (y_pred - y_true) / y_true.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Activation):\n",
    "    def __init__(self):\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def sigmoid_prime(x):\n",
    "            s = sigmoid(x)\n",
    "            return s * (1 - s)\n",
    "\n",
    "        super().__init__(sigmoid, sigmoid_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCrossEntropy(Loss):\n",
    "    def loss(self, y_true, y_pred):\n",
    "        epsilon = 1e-7\n",
    "        return -np.mean(np.multiply(y_true, np.log(y_pred + epsilon)) + np.multiply(1 - y_true, np.log(1 - y_pred + epsilon)))\n",
    "\n",
    "    def gradient(self, y_true, y_pred):\n",
    "        epsilon = 1e-7\n",
    "        return np.divide(y_pred - y_true, np.multiply(y_pred + epsilon, 1 - y_pred + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(Layer):\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def backward(self, output_error, learning_rate):\n",
    "        for layer in reversed(self.layers):\n",
    "            output_error = layer.backward(output_error, learning_rate)\n",
    "        return output_error\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, network, loss):\n",
    "        self.network = Network(network)\n",
    "        self.loss = loss\n",
    "    \n",
    "    def train(self, x_train, y_train, epochs, learning_rate, verbose=False):\n",
    "        for epoch in range(epochs):\n",
    "            for x, y in zip(x_train, y_train):\n",
    "                output = self.network.forward(x)\n",
    "                loss = self.loss.loss(y, output)\n",
    "                loss_gradient = self.loss.gradient(y, output)\n",
    "                self.network.backward(loss_gradient, learning_rate)\n",
    "            if verbose:\n",
    "                mean_loss = 0\n",
    "                for x, y in zip(x_train, y_train):\n",
    "                    output = self.network.forward(x)\n",
    "                    loss = self.loss.loss(y, output)\n",
    "                    mean_loss += loss\n",
    "                mean_loss /= len(x_train)\n",
    "                print(f\"Epoch {epoch + 1}/{epochs} loss: {round(mean_loss, 4)}\")\n",
    "                test_model(self, x_train, y_train)\n",
    "    \n",
    "    def predict_one(self, x_test):\n",
    "        return self.network.forward(x_test)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        y_pred = []\n",
    "        for x in x_test:\n",
    "            y_pred.append(self.network.forward(x))\n",
    "        return np.array(y_pred).squeeze()\n",
    "\n",
    "    def save(self, path):\n",
    "        np.save(path, self.network)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.network = np.load(path, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_data(x, y, limit):\n",
    "#     x = x.reshape(x.shape[0], 28 * 28, 1)\n",
    "#     x = x.astype(\"float32\") / 255\n",
    "#     y = np.eye(10)[y]\n",
    "#     y = y.reshape(y.shape[0], 10, 1)\n",
    "#     return x[:limit], y[:limit]\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train, y_train = preprocess_data(x_train, y_train, 10000)\n",
    "# x_test, y_test = preprocess_data(x_test, y_test, 1000)\n",
    "\n",
    "# # neural network\n",
    "# layers = [\n",
    "#     Dense(28 * 28, 40),\n",
    "#     Tanh(),\n",
    "#     Dense(40, 10),\n",
    "#     Sigmoid()\n",
    "# ]\n",
    "\n",
    "# model = Model(layers, BinaryCrossEntropy())\n",
    "# model.train(x_train, y_train, 10, 0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct = 0\n",
    "# for x, y in zip(x_test, y_test):\n",
    "#     output = model.predict_one(x)\n",
    "#     # print(\"Prediction: %d, Ground Truth: %d\" % (np.argmax(output), np.argmax(y)))\n",
    "#     if np.argmax(output) == np.argmax(y):\n",
    "#         correct += 1\n",
    "# print(\"Accuracy: %.3f\" % (correct / len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosen = randint(0, 1000)\n",
    "# plt.imshow(x_test[choosen].reshape(28, 28), cmap=\"gray\")\n",
    "# prediction = model.predict_one(x_test[choosen])\n",
    "# for i in range(10):\n",
    "#     print(i, \":\", round(prediction[i][0], 3))\n",
    "# print(\"Prediction:\", np.argmax(prediction))\n",
    "# print(\"Ground Truth:\", np.argmax(y_test[choosen]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x_test, y_test):\n",
    "    correct = 0\n",
    "    for x, y in zip(x_test, y_test):\n",
    "        output = model.predict_one(x)\n",
    "        # print(\"Output:\", output)\n",
    "        # print(\"Prediction: %d, Ground Truth: %d\" % (np.argmax(output), np.argmax(y)))\n",
    "        if np.argmax(output) == np.argmax(y):\n",
    "            correct += 1\n",
    "    print(\"Accuracy: %.3f\" % (correct / len(x_test)))\n",
    "# test_model(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Parsing import Parsing\n",
    "\n",
    "# parser = Parsing()\n",
    "# (x_train, y_train), (x_test, y_test) = parser.getData(0.8)\n",
    "\n",
    "# def preprocess_data(x, y):\n",
    "#     x = np.asarray(x)\n",
    "#     x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "#     y = np.asarray(y)\n",
    "#     y = y.reshape(y.shape[0], y.shape[1], 1)\n",
    "#     return x, y\n",
    "\n",
    "# x_train, y_train = preprocess_data(x_train, y_train)\n",
    "# x_test, y_test = preprocess_data(x_test, y_test)\n",
    "# print(\"X train shape:\", x_train.shape)\n",
    "# print(\"Y train shape:\", y_train.shape)\n",
    "# print(\"X test shape:\", x_test.shape)\n",
    "# print(\"Y test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = [\n",
    "#     Dense(389, 64),\n",
    "#     Tanh(),\n",
    "#     Dense(64, 4),\n",
    "#     Sigmoid()\n",
    "# ]\n",
    "\n",
    "# model = Model(layers, BinaryCrossEntropy())\n",
    "# model.train(x_train, y_train, 10, 0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 64)\n",
      "(6000, 4)\n"
     ]
    }
   ],
   "source": [
    "from parsingHenry import Ld\n",
    "\n",
    "ld = Ld()\n",
    "ld.loadinput(\"datasets/chess_positions.txt\", \"train\")\n",
    "print(ld.input.shape)\n",
    "print(ld.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.233\n",
      "Epoch 1/50 loss: 3.1695\n",
      "Accuracy: 0.327\n",
      "Epoch 2/50 loss: 2.6806\n",
      "Accuracy: 0.380\n",
      "Epoch 3/50 loss: 2.4024\n",
      "Accuracy: 0.414\n",
      "Epoch 4/50 loss: 2.1992\n",
      "Accuracy: 0.442\n",
      "Epoch 5/50 loss: 2.048\n",
      "Accuracy: 0.465\n",
      "Epoch 6/50 loss: 1.922\n",
      "Accuracy: 0.485\n",
      "Epoch 7/50 loss: 1.8131\n",
      "Accuracy: 0.504\n",
      "Epoch 8/50 loss: 1.7191\n",
      "Accuracy: 0.518\n",
      "Epoch 9/50 loss: 1.6345\n",
      "Accuracy: 0.533\n",
      "Epoch 10/50 loss: 1.5578\n",
      "Accuracy: 0.548\n",
      "Epoch 11/50 loss: 1.4888\n",
      "Accuracy: 0.564\n",
      "Epoch 12/50 loss: 1.4271\n",
      "Accuracy: 0.574\n",
      "Epoch 13/50 loss: 1.372\n",
      "Accuracy: 0.585\n",
      "Epoch 14/50 loss: 1.3207\n",
      "Accuracy: 0.596\n",
      "Epoch 15/50 loss: 1.272\n",
      "Accuracy: 0.606\n",
      "Epoch 16/50 loss: 1.2286\n",
      "Accuracy: 0.617\n",
      "Epoch 17/50 loss: 1.1885\n",
      "Accuracy: 0.627\n",
      "Epoch 18/50 loss: 1.151\n",
      "Accuracy: 0.634\n",
      "Epoch 19/50 loss: 1.1153\n",
      "Accuracy: 0.642\n",
      "Epoch 20/50 loss: 1.0821\n",
      "Accuracy: 0.650\n",
      "Epoch 21/50 loss: 1.05\n",
      "Accuracy: 0.658\n",
      "Epoch 22/50 loss: 1.0194\n",
      "Accuracy: 0.663\n",
      "Epoch 23/50 loss: 0.9911\n",
      "Accuracy: 0.671\n",
      "Epoch 24/50 loss: 0.965\n",
      "Accuracy: 0.678\n",
      "Epoch 25/50 loss: 0.9395\n",
      "Accuracy: 0.683\n",
      "Epoch 26/50 loss: 0.9155\n",
      "Accuracy: 0.691\n",
      "Epoch 27/50 loss: 0.892\n",
      "Accuracy: 0.697\n",
      "Epoch 28/50 loss: 0.8699\n",
      "Accuracy: 0.702\n",
      "Epoch 29/50 loss: 0.8488\n",
      "Accuracy: 0.707\n",
      "Epoch 30/50 loss: 0.8293\n",
      "Accuracy: 0.713\n",
      "Epoch 31/50 loss: 0.8108\n",
      "Accuracy: 0.720\n",
      "Epoch 32/50 loss: 0.7933\n",
      "Accuracy: 0.726\n",
      "Epoch 33/50 loss: 0.7764\n",
      "Accuracy: 0.732\n",
      "Epoch 34/50 loss: 0.7598\n",
      "Accuracy: 0.738\n",
      "Epoch 35/50 loss: 0.7438\n",
      "Accuracy: 0.744\n",
      "Epoch 36/50 loss: 0.7286\n",
      "Accuracy: 0.749\n",
      "Epoch 37/50 loss: 0.714\n",
      "Accuracy: 0.753\n",
      "Epoch 38/50 loss: 0.6998\n",
      "Accuracy: 0.758\n",
      "Epoch 39/50 loss: 0.6861\n",
      "Accuracy: 0.762\n",
      "Epoch 40/50 loss: 0.6727\n",
      "Accuracy: 0.766\n",
      "Epoch 41/50 loss: 0.6598\n",
      "Accuracy: 0.770\n",
      "Epoch 42/50 loss: 0.6473\n",
      "Accuracy: 0.774\n",
      "Epoch 43/50 loss: 0.6353\n",
      "Accuracy: 0.776\n",
      "Epoch 44/50 loss: 0.6237\n",
      "Accuracy: 0.780\n",
      "Epoch 45/50 loss: 0.6126\n",
      "Accuracy: 0.784\n",
      "Epoch 46/50 loss: 0.6017\n",
      "Accuracy: 0.787\n",
      "Epoch 47/50 loss: 0.5911\n",
      "Accuracy: 0.790\n",
      "Epoch 48/50 loss: 0.5808\n",
      "Accuracy: 0.793\n",
      "Epoch 49/50 loss: 0.5706\n",
      "Accuracy: 0.797\n",
      "Epoch 50/50 loss: 0.5608\n",
      "Accuracy: 0.800\n",
      "Accuracy: 0.800\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(x, y):\n",
    "    x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "    y = y.reshape(y.shape[0], y.shape[1], 1)\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = preprocess_data(ld.input, ld.target)\n",
    "\n",
    "layers = [\n",
    "    Dense(64, 200),\n",
    "    Tanh(),\n",
    "    Dense(200, 200),\n",
    "    Tanh(),\n",
    "    Dense(200, 4),\n",
    "    Sigmoid()\n",
    "]\n",
    "\n",
    "model = Model(layers, BinaryCrossEntropy())\n",
    "test_model(model, x_train, y_train)\n",
    "model.train(x_train, y_train, 50, 0.0001, verbose=True)\n",
    "test_model(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random index: 20\n",
      "[[12  0  0  3  0  8  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 10  7  0  0]\n",
      " [ 0  0  2  6  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Prediction: [[9.60293678e-01]\n",
      " [9.59951651e-01]\n",
      " [5.37284432e-04]\n",
      " [4.46223219e-01]]\n",
      "Real: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "random_index = randint(0, len(x_train))\n",
    "pred = model.predict_one(x_train[random_index])\n",
    "real = y_train[random_index]\n",
    "\n",
    "print(\"Random index:\", random_index)\n",
    "print(x_train[random_index].reshape(8, 8))\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Real:\", real)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
